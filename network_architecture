GACNet(
  (sa1): GraphAttentionConvLayer(
    (mlp_convs): ModuleList(
      (0): Conv2d(9, 32, kernel_size=(1, 1), stride=(1, 1))
      (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
      (2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))
    )
    (mlp_bns): ModuleList(
      (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (GAT): GraphAttention(
      (leakyrelu): LeakyReLU(negative_slope=0.2)
    )
  )
  (sa2): GraphAttentionConvLayer(
    (mlp_convs): ModuleList(
      (0): Conv2d(67, 64, kernel_size=(1, 1), stride=(1, 1))
      (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
      (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
    )
    (mlp_bns): ModuleList(
      (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (GAT): GraphAttention(
      (leakyrelu): LeakyReLU(negative_slope=0.2)
    )
  )
  (sa3): GraphAttentionConvLayer(
    (mlp_convs): ModuleList(
      (0): Conv2d(131, 128, kernel_size=(1, 1), stride=(1, 1))
      (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (mlp_bns): ModuleList(
      (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (GAT): GraphAttention(
      (leakyrelu): LeakyReLU(negative_slope=0.2)
    )
  )
  (sa4): GraphAttentionConvLayer(
    (mlp_convs): ModuleList(
      (0): Conv2d(259, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (2): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))
    )
    (mlp_bns): ModuleList(
      (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (GAT): GraphAttention(
      (leakyrelu): LeakyReLU(negative_slope=0.2)
    )
  )
  (fp4): PointNetFeaturePropagation(
    (mlp_convs): ModuleList(
      (0): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
      (1): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
    )
    (mlp_bns): ModuleList(
      (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (fp3): PointNetFeaturePropagation(
    (mlp_convs): ModuleList(
      (0): Conv1d(384, 256, kernel_size=(1,), stride=(1,))
      (1): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
    )
    (mlp_bns): ModuleList(
      (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (fp2): PointNetFeaturePropagation(
    (mlp_convs): ModuleList(
      (0): Conv1d(320, 256, kernel_size=(1,), stride=(1,))
      (1): Conv1d(256, 128, kernel_size=(1,), stride=(1,))
    )
    (mlp_bns): ModuleList(
      (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (fp1): PointNetFeaturePropagation(
    (mlp_convs): ModuleList(
      (0): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
      (1): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
      (2): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
    )
    (mlp_bns): ModuleList(
      (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (conv1): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (drop1): Dropout(p=0, inplace=False)
  (conv2): Conv1d(128, 13, kernel_size=(1,), stride=(1,))
)



some input data can be seen here.
torch.Size([24, 3, 4096])
torch.float32
tensor([[[ 1.4000e-01,  2.6800e-01,  2.5800e-01,  ...,  3.0800e-01,
           1.4300e-01,  3.6100e-01],
         [-3.8600e-01, -3.5400e-01, -1.9300e-01,  ...,  1.2300e-01,
           3.3000e-02,  4.5300e-01],
         [ 3.4480e+00,  5.2100e-01,  1.0220e+00,  ...,  1.0860e+00,
           9.2000e-01,  1.1010e+00]],

        [[ 3.0300e-01,  3.0000e-01,  1.6600e-01,  ...,  6.4000e-02,
          -1.7800e-01, -8.5000e-02],
         [ 4.3000e-01,  2.7000e-01,  4.2000e-02,  ...,  4.7900e-01,
          -2.9000e-02,  4.5100e-01],
         [ 5.1500e-01,  1.8440e+00,  3.3200e-01,  ...,  2.2040e+00,
           2.5000e-02,  2.2020e+00]],

        [[-4.9100e-01, -2.9800e-01, -4.2000e-01,  ...,  8.6000e-02,
          -4.9500e-01, -4.9600e-01],
         [ 7.0000e-03,  4.3000e-02, -4.1000e-02,  ..., -1.5000e-01,
          -5.3000e-02,  3.0700e-01],
         [ 2.1420e+00,  4.4080e+00,  7.6700e-01,  ...,  4.2870e+00,
           3.3380e+00,  2.9980e+00]],

        ...,

        [[ 2.5000e-01, -4.8900e-01, -4.9200e-01,  ..., -4.9000e-01,
           2.3400e-01,  4.8600e-01],
         [-2.3600e-01, -2.3500e-01,  3.4000e-01,  ...,  3.4600e-01,
           3.8000e-01, -3.0700e-01],
         [ 1.1000e-02,  4.6600e-01,  8.4000e-01,  ...,  6.3400e-01,
           1.5000e-02,  2.6870e+00]],

        [[-4.1800e-01, -4.7800e-01, -4.2900e-01,  ...,  1.0000e-01,
          -2.9200e-01,  8.2000e-02],
         [ 2.4000e-02,  2.0100e-01, -1.6800e-01,  ...,  4.7700e-01,
           2.0300e-01, -4.9000e-01],
         [ 1.2540e+00,  1.7610e+00,  1.8760e+00,  ...,  7.4200e-01,
           7.4300e-01,  2.8770e+00]],

        [[-2.6800e-01, -2.3600e-01, -1.1600e-01,  ..., -4.5400e-01,
          -6.9000e-02, -2.8600e-01],
         [ 4.5000e-02,  5.2000e-02, -3.4600e-01,  ..., -4.3300e-01,
          -1.8500e-01, -1.7000e-02],
         [ 7.9700e-01,  1.1370e+00,  2.6260e+00,  ...,  2.9800e-01,
           1.0000e-03,  5.5900e-01]]], device='cuda:0')
torch.Size([24, 6, 4096])
torch.float32
tensor([[[7.4902e-01, 9.0196e-02, 5.7647e-01,  ..., 5.6078e-01,
          5.8824e-01, 5.4902e-01],
         [7.6471e-01, 9.0196e-02, 5.4510e-01,  ..., 5.1373e-01,
          5.4118e-01, 5.0980e-01],
         [7.7647e-01, 8.2353e-02, 4.6275e-01,  ..., 4.1176e-01,
          4.4706e-01, 4.1176e-01],
         [7.4355e-01, 7.5139e-01, 7.5078e-01,  ..., 7.5384e-01,
          7.4374e-01, 7.5709e-01],
         [4.6630e-01, 4.6856e-01, 4.7991e-01,  ..., 5.0219e-01,
          4.9584e-01, 5.2545e-01],
         [9.1193e-01, 1.3779e-01, 2.7030e-01,  ..., 2.8723e-01,
          2.4332e-01, 2.9119e-01]],

        [[7.0588e-01, 6.5490e-01, 1.5294e-01,  ..., 4.3137e-01,
          2.5490e-01, 4.4706e-01],
         [6.9804e-01, 6.4314e-01, 1.5686e-01,  ..., 4.0784e-01,
          2.6667e-01, 4.2353e-01],
         [6.5098e-01, 5.7647e-01, 1.6471e-01,  ..., 3.6078e-01,
          2.0000e-01, 3.6863e-01],
         [9.8964e-01, 9.8917e-01, 9.6813e-01,  ..., 9.5211e-01,
          9.1412e-01, 9.2872e-01],
         [8.5508e-01, 7.9880e-01, 7.1861e-01,  ..., 8.7232e-01,
          6.9363e-01, 8.6247e-01],
         [1.7765e-01, 6.3608e-01, 1.1452e-01,  ..., 7.6026e-01,
          8.6237e-03, 7.5957e-01]],

        [[5.7255e-01, 6.3137e-01, 4.5490e-01,  ..., 5.9216e-01,
          5.6863e-01, 5.9608e-01],
         [6.1961e-01, 5.6471e-01, 6.0784e-01,  ..., 5.6471e-01,
          5.4902e-01, 5.8039e-01],
         [6.1176e-01, 4.5490e-01, 8.3922e-01,  ..., 4.9412e-01,
          4.6275e-01, 5.3725e-01],
         [1.8993e-03, 3.8557e-02, 1.5385e-02,  ..., 1.1149e-01,
          1.1396e-03, 9.4967e-04],
         [5.5185e-01, 5.5751e-01, 5.4430e-01,  ..., 5.2714e-01,
          5.4241e-01, 5.9906e-01],
         [4.0507e-01, 8.3359e-01, 1.4505e-01,  ..., 8.1070e-01,
          6.3124e-01, 5.6694e-01]],

        ...,

        [[4.0784e-01, 6.9804e-01, 6.3922e-01,  ..., 6.5098e-01,
          4.0784e-01, 5.8431e-01],
         [4.3529e-01, 7.0196e-01, 6.6667e-01,  ..., 6.9020e-01,
          4.1961e-01, 5.6471e-01],
         [4.0784e-01, 6.4706e-01, 6.3529e-01,  ..., 6.4706e-01,
          3.7647e-01, 5.5294e-01],
         [2.2275e-01, 3.2670e-03, 2.3760e-03,  ..., 2.9700e-03,
          2.1800e-01, 2.9284e-01],
         [3.6191e-01, 3.6239e-01, 6.3477e-01,  ..., 6.3761e-01,
          6.5372e-01, 3.2828e-01],
         [4.0726e-03, 1.7253e-01, 3.1100e-01,  ..., 2.3473e-01,
          5.5535e-03, 9.9482e-01]],

        [[7.2941e-01, 5.5294e-01, 6.9804e-01,  ..., 7.0196e-01,
          6.7059e-01, 6.1176e-01],
         [6.3922e-01, 5.3725e-01, 5.8431e-01,  ..., 6.1961e-01,
          5.7255e-01, 4.7059e-01],
         [4.7451e-01, 5.0196e-01, 4.1176e-01,  ..., 5.4510e-01,
          4.9412e-01, 2.8235e-01],
         [3.8868e-02, 2.5069e-02, 3.6339e-02,  ..., 1.5800e-01,
          6.7847e-02, 1.5386e-01],
         [1.8410e-01, 2.4423e-01, 1.1889e-01,  ..., 3.3798e-01,
          2.4490e-01, 9.5109e-03],
         [3.8058e-01, 5.3445e-01, 5.6935e-01,  ..., 2.2519e-01,
          2.2549e-01, 8.7314e-01]],

        [[6.1569e-01, 9.8039e-02, 4.8627e-01,  ..., 9.3725e-01,
          5.3333e-01, 1.3333e-01],
         [6.1176e-01, 9.4118e-02, 4.5098e-01,  ..., 9.4118e-01,
          5.4902e-01, 1.5294e-01],
         [5.2941e-01, 8.6275e-02, 3.2157e-01,  ..., 8.7059e-01,
          4.5882e-01, 1.2549e-01],
         [8.1418e-01, 8.1968e-01, 8.4033e-01,  ..., 7.8217e-01,
          8.4842e-01, 8.1108e-01],
         [4.5914e-01, 4.6040e-01, 3.8860e-01,  ..., 3.7290e-01,
          4.1764e-01, 4.4795e-01],
         [2.8741e-01, 4.1003e-01, 9.4699e-01,  ..., 1.0746e-01,
          3.6062e-04, 2.0159e-01]]], device='cuda:0')
